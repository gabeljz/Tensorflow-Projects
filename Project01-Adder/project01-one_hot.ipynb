{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_to_vector(number):\n",
    "    # print(number)\n",
    "    number_vector = np.zeros(101, dtype=np.int_)\n",
    "    # print(number_vector)\n",
    "    number_vector[number] = 1\n",
    "    # print(number_vector)\n",
    "    return np.array(number_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "200\n",
      "10201\n",
      "10201\n"
     ]
    }
   ],
   "source": [
    "operand = np.arange(0, 101);\n",
    "sums = []\n",
    "for operand1 in operand:\n",
    "    for operand2 in operand:\n",
    "        sums.append(operand1 + operand2)\n",
    "\n",
    "# print(operand[0])\n",
    "# operand = keras.utils.to_categorical(operand, 101);\n",
    "# print(operand[0])\n",
    "# print(operand[1])\n",
    "# print(operand[100])\n",
    "\n",
    "operands = []\n",
    "for operand1 in operand:\n",
    "    for operand2 in operand:\n",
    "        operands.append(np.concatenate((number_to_vector(operand1), number_to_vector(operand2)), axis=0))\n",
    "\n",
    "print(operands[10200])\n",
    "print(sums[10200])\n",
    "print(len(operands))\n",
    "print(len(sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(sums[0])\n",
    "n_classes = 201;\n",
    "sums = keras.utils.to_categorical(sums, n_classes)\n",
    "print(sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8209 9011  873 ..., 2043 4529 1553]\n",
      "[8209 9011  873 ..., 1346  548 1712]\n",
      "[8018 7782 1835 ..., 2043 4529 1553]\n",
      "(8160, 202)\n",
      "(8160, 201)\n",
      "(2041, 202)\n",
      "(2041, 201)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "operands = np.array(operands)\n",
    "sums = np.array(sums)\n",
    "\n",
    "number_of_records = len(operands)\n",
    "shuffle = np.arange(number_of_records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.8\n",
    "\n",
    "print(shuffle)\n",
    "#print(int(number_of_records*test_fraction))\n",
    "\n",
    "#making a train / test split\n",
    "train_split, test_split = shuffle[:int(number_of_records*test_fraction)], shuffle[int(number_of_records*test_fraction):]\n",
    "print(train_split)\n",
    "print(test_split)\n",
    "x_train , y_train = operands[train_split,:] , sums[train_split]\n",
    "x_test , y_test = operands[test_split,:] , sums[test_split]\n",
    "\n",
    "# x_train, y_train = word_vectors[train_split,:], labels.values[train_split,:]\n",
    "# x_test, y_test = word_vectors[test_split,:], labels.values[test_split]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "# type(x_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic MNIST \n",
    "learning_rate = 0.1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 202 # MNIST data input (img shape: 28*28 flattened to be 784)\n",
    "n_hidden_1 = 202 # 1st layer number of neurons\n",
    "n_hidden_2 = 202 # 2nd layer number of neurons\n",
    "n_hidden_3 = 202 # 2nd layer number of neurons\n",
    "n_classes = 201 # MNIST classes for prediction(digits 0-9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(n_input,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp)\n",
    "# x = Dropout(0.8)(x)\n",
    "# x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "# x = Dropout(0.8)(x)\n",
    "# x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 202)               0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 202)               41006     \n",
      "_________________________________________________________________\n",
      "Outputlayer (Dense)          (None, 201)               40803     \n",
      "=================================================================\n",
      "Total params: 81,809\n",
      "Trainable params: 81,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(Inp, output)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic MNIST \n",
    "training_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8160 samples, validate on 2041 samples\n",
      "Epoch 1/100\n",
      "8160/8160 [==============================] - 0s - loss: 5.2481 - acc: 0.0075 - val_loss: 5.2011 - val_acc: 0.0054\n",
      "Epoch 2/100\n",
      "8160/8160 [==============================] - 0s - loss: 5.1089 - acc: 0.0096 - val_loss: 5.1592 - val_acc: 0.0054\n",
      "Epoch 3/100\n",
      "8160/8160 [==============================] - 0s - loss: 5.0328 - acc: 0.0125 - val_loss: 5.1333 - val_acc: 0.0024\n",
      "Epoch 4/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.9510 - acc: 0.0130 - val_loss: 5.0725 - val_acc: 0.0024\n",
      "Epoch 5/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.8271 - acc: 0.0163 - val_loss: 4.9570 - val_acc: 9.7991e-04\n",
      "Epoch 6/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.6573 - acc: 0.0238 - val_loss: 4.8087 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.4825 - acc: 0.0342 - val_loss: 4.6839 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.3287 - acc: 0.0403 - val_loss: 4.5728 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.1944 - acc: 0.0478 - val_loss: 4.4858 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "8160/8160 [==============================] - 0s - loss: 4.0784 - acc: 0.0623 - val_loss: 4.4309 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.9776 - acc: 0.0645 - val_loss: 4.3746 - val_acc: 4.8996e-04\n",
      "Epoch 12/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.8860 - acc: 0.0732 - val_loss: 4.3465 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.8058 - acc: 0.0786 - val_loss: 4.3193 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.7328 - acc: 0.0873 - val_loss: 4.3064 - val_acc: 4.8996e-04\n",
      "Epoch 15/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.6647 - acc: 0.1034 - val_loss: 4.2968 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.6025 - acc: 0.0998 - val_loss: 4.2840 - val_acc: 4.8996e-04\n",
      "Epoch 17/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.5409 - acc: 0.1142 - val_loss: 4.2882 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.4843 - acc: 0.1248 - val_loss: 4.2863 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.4277 - acc: 0.1306 - val_loss: 4.2937 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.3766 - acc: 0.1488 - val_loss: 4.3152 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.3245 - acc: 0.1537 - val_loss: 4.3314 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.2762 - acc: 0.1692 - val_loss: 4.3292 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.2261 - acc: 0.1828 - val_loss: 4.3552 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.1779 - acc: 0.1895 - val_loss: 4.3886 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.1354 - acc: 0.2036 - val_loss: 4.3893 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.0875 - acc: 0.2178 - val_loss: 4.4181 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "8160/8160 [==============================] - 0s - loss: 3.0413 - acc: 0.2295 - val_loss: 4.4429 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.9943 - acc: 0.2471 - val_loss: 4.4685 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.9519 - acc: 0.2604 - val_loss: 4.4964 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.9052 - acc: 0.2755 - val_loss: 4.5283 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.8613 - acc: 0.2866 - val_loss: 4.5444 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.8163 - acc: 0.3018 - val_loss: 4.5666 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.7703 - acc: 0.3270 - val_loss: 4.5858 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.7273 - acc: 0.3346 - val_loss: 4.6055 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.6763 - acc: 0.3600 - val_loss: 4.6371 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.6313 - acc: 0.3652 - val_loss: 4.6652 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.5857 - acc: 0.3850 - val_loss: 4.6830 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.5387 - acc: 0.4091 - val_loss: 4.7099 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.4929 - acc: 0.4202 - val_loss: 4.7278 - val_acc: 4.8996e-04\n",
      "Epoch 40/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.4450 - acc: 0.4363 - val_loss: 4.7456 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.3970 - acc: 0.4569 - val_loss: 4.7710 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.3474 - acc: 0.4719 - val_loss: 4.7812 - val_acc: 4.8996e-04\n",
      "Epoch 43/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.3023 - acc: 0.4869 - val_loss: 4.8066 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.2541 - acc: 0.5010 - val_loss: 4.8269 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.2024 - acc: 0.5275 - val_loss: 4.8438 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.1557 - acc: 0.5429 - val_loss: 4.8597 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.1106 - acc: 0.5490 - val_loss: 4.8673 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.0571 - acc: 0.5734 - val_loss: 4.8883 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "8160/8160 [==============================] - 0s - loss: 2.0115 - acc: 0.5849 - val_loss: 4.9074 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.9579 - acc: 0.6081 - val_loss: 4.8996 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.9068 - acc: 0.6200 - val_loss: 4.9138 - val_acc: 4.8996e-04\n",
      "Epoch 52/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.8595 - acc: 0.6373 - val_loss: 4.9283 - val_acc: 4.8996e-04\n",
      "Epoch 53/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.8134 - acc: 0.6502 - val_loss: 4.9283 - val_acc: 4.8996e-04\n",
      "Epoch 54/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.7607 - acc: 0.6707 - val_loss: 4.9318 - val_acc: 4.8996e-04\n",
      "Epoch 55/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.7086 - acc: 0.6866 - val_loss: 4.9392 - val_acc: 4.8996e-04\n",
      "Epoch 56/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.6603 - acc: 0.7048 - val_loss: 4.9494 - val_acc: 9.7991e-04\n",
      "Epoch 57/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.6105 - acc: 0.7200 - val_loss: 4.9349 - val_acc: 4.8996e-04\n",
      "Epoch 58/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.5600 - acc: 0.7369 - val_loss: 4.9530 - val_acc: 0.0024\n",
      "Epoch 59/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.5121 - acc: 0.7483 - val_loss: 4.9557 - val_acc: 9.7991e-04\n",
      "Epoch 60/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.4614 - acc: 0.7706 - val_loss: 4.9557 - val_acc: 0.0015\n",
      "Epoch 61/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.4156 - acc: 0.7803 - val_loss: 4.9501 - val_acc: 0.0024\n",
      "Epoch 62/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.3673 - acc: 0.7973 - val_loss: 4.9362 - val_acc: 0.0020\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8160/8160 [==============================] - 0s - loss: 1.3195 - acc: 0.8056 - val_loss: 4.9349 - val_acc: 0.0029\n",
      "Epoch 64/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.2718 - acc: 0.8216 - val_loss: 4.9347 - val_acc: 0.0049\n",
      "Epoch 65/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.2273 - acc: 0.8325 - val_loss: 4.9300 - val_acc: 0.0044\n",
      "Epoch 66/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.1809 - acc: 0.8488 - val_loss: 4.9146 - val_acc: 0.0029\n",
      "Epoch 67/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.1360 - acc: 0.8577 - val_loss: 4.9104 - val_acc: 0.0054\n",
      "Epoch 68/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.0907 - acc: 0.8676 - val_loss: 4.9033 - val_acc: 0.0064\n",
      "Epoch 69/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.0495 - acc: 0.8789 - val_loss: 4.8961 - val_acc: 0.0054\n",
      "Epoch 70/100\n",
      "8160/8160 [==============================] - 0s - loss: 1.0049 - acc: 0.8918 - val_loss: 4.8961 - val_acc: 0.0064\n",
      "Epoch 71/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.9629 - acc: 0.9007 - val_loss: 4.8571 - val_acc: 0.0064\n",
      "Epoch 72/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.9258 - acc: 0.9058 - val_loss: 4.8527 - val_acc: 0.0093\n",
      "Epoch 73/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.8839 - acc: 0.9162 - val_loss: 4.8535 - val_acc: 0.0083\n",
      "Epoch 74/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.8460 - acc: 0.9259 - val_loss: 4.8412 - val_acc: 0.0103\n",
      "Epoch 75/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.8107 - acc: 0.9326 - val_loss: 4.8170 - val_acc: 0.0103\n",
      "Epoch 76/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.7716 - acc: 0.9431 - val_loss: 4.8108 - val_acc: 0.0118\n",
      "Epoch 77/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.7372 - acc: 0.9442 - val_loss: 4.7996 - val_acc: 0.0108\n",
      "Epoch 78/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.7025 - acc: 0.9534 - val_loss: 4.7764 - val_acc: 0.0142\n",
      "Epoch 79/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.6696 - acc: 0.9556 - val_loss: 4.7811 - val_acc: 0.0147\n",
      "Epoch 80/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.6381 - acc: 0.9642 - val_loss: 4.7618 - val_acc: 0.0157\n",
      "Epoch 81/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.6074 - acc: 0.9678 - val_loss: 4.7450 - val_acc: 0.0186\n",
      "Epoch 82/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.5772 - acc: 0.9730 - val_loss: 4.7263 - val_acc: 0.0167\n",
      "Epoch 83/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.5502 - acc: 0.9754 - val_loss: 4.7079 - val_acc: 0.0191\n",
      "Epoch 84/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.5214 - acc: 0.9777 - val_loss: 4.6925 - val_acc: 0.0186\n",
      "Epoch 85/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.4964 - acc: 0.9808 - val_loss: 4.7034 - val_acc: 0.0235\n",
      "Epoch 86/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.4700 - acc: 0.9849 - val_loss: 4.6739 - val_acc: 0.0250\n",
      "Epoch 87/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.4454 - acc: 0.9880 - val_loss: 4.6588 - val_acc: 0.0269\n",
      "Epoch 88/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.4237 - acc: 0.9884 - val_loss: 4.6474 - val_acc: 0.0284\n",
      "Epoch 89/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.4019 - acc: 0.9902 - val_loss: 4.6329 - val_acc: 0.0318\n",
      "Epoch 90/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.3800 - acc: 0.9919 - val_loss: 4.6278 - val_acc: 0.0333\n",
      "Epoch 91/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.3599 - acc: 0.9934 - val_loss: 4.6111 - val_acc: 0.0367\n",
      "Epoch 92/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.3404 - acc: 0.9947 - val_loss: 4.6006 - val_acc: 0.0431\n",
      "Epoch 93/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.3221 - acc: 0.9962 - val_loss: 4.5891 - val_acc: 0.0397\n",
      "Epoch 94/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.3052 - acc: 0.9961 - val_loss: 4.5769 - val_acc: 0.0475\n",
      "Epoch 95/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2896 - acc: 0.9972 - val_loss: 4.5606 - val_acc: 0.0461\n",
      "Epoch 96/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2736 - acc: 0.9972 - val_loss: 4.5460 - val_acc: 0.0495\n",
      "Epoch 97/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2591 - acc: 0.9984 - val_loss: 4.5398 - val_acc: 0.0524\n",
      "Epoch 98/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2449 - acc: 0.9984 - val_loss: 4.5212 - val_acc: 0.0510\n",
      "Epoch 99/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2322 - acc: 0.9988 - val_loss: 4.5130 - val_acc: 0.0578\n",
      "Epoch 100/100\n",
      "8160/8160 [==============================] - 0s - loss: 0.2188 - acc: 0.9993 - val_loss: 4.4985 - val_acc: 0.0563\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUoKBRERqaRQEBGRSgoFERGp9P9tvC4vm3rmmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11900c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_train[10:15])\n",
    "print(np.argmax(preds))\n",
    "print(np.argmax(y_train[10:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets import our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('./imdb_data/reviews.txt', header=None)\n",
    "labels = pd.read_csv('./imdb_data/labels_ohe.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brilliant over  acting by lesley ann warren . best dramatic hobo lady i have ever seen  and love scenes in clothes warehouse are second to none . the corn on face is a classic  as good as anything in blazing saddles . the take on lawyers is also superb . after being accused of being a turncoat  selling out his boss  and being dishonest the lawyer of pepto bolt shrugs indifferently  i  m a lawyer  he says . three funny words . jeffrey tambor  a favorite from the later larry sanders show  is fantastic here too as a mad millionaire who wants to crush the ghetto . his character is more malevolent than usual . the hospital scene  and the scene where the homeless invade a demolition site  are all  time classics . look for the legs scene and the two big diggers fighting  one bleeds  . this movie gets better each time i see it  which is quite often  .  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()\n",
    "reviews[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  0.0  1.0\n",
       "1  1.0  0.0\n",
       "2  0.0  1.0\n",
       "3  1.0  0.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels[:5]\n",
    "# 0 = bad 1 = good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    }
   ],
   "source": [
    "total_counts = Counter()\n",
    "for i,row in reviews.iterrows():\n",
    "    total_counts.update(row[0].split(' '))\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just keeping the 10k most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'there', 'her', 'or', 'just', 'about', 'out', 'if', 'has', 'what']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the :  336713\n"
     ]
    }
   ],
   "source": [
    "print(vocab[1], ': ', total_counts[vocab[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our word index table\n",
    "\n",
    "we can input a word it gives back the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(vocab)} #dictionary comprehension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['good']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the a review to a vector of words 10k long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vector = np.zeros(len(vocab), dtype=np.int_)\n",
    "    for word in text.split(' '):\n",
    "        idx = word2idx.get(word,None)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        else:\n",
    "            word_vector[idx] = 1 # was += 1\n",
    "    return np.array(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('There were lots of good movies and stars this year')[:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_vector = text_to_vector('There were lots of good movies and stars this year')\n",
    "test_word_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do that for the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1]]\n",
      "                                                   0\n",
      "0  bromwell high is a cartoon comedy . it ran at ...\n",
      "1  story of a man who has unnatural feelings for ...\n",
      "2  homelessness  or houselessness as george carli...\n"
     ]
    }
   ],
   "source": [
    "# Printing out the first 3 word vectors\n",
    "print(word_vectors[:3, :25])\n",
    "print(reviews[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what our tensor looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10000)\n",
      "(20000, 2)\n",
      "(5000, 10000)\n",
      "(5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "number_of_records = len(labels)\n",
    "shuffle = np.arange(number_of_records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.8\n",
    "\n",
    "#print(int(number_of_records*test_fraction))\n",
    "\n",
    "#making a train / test split\n",
    "train_split, test_split = shuffle[:int(number_of_records*test_fraction)], shuffle[int(number_of_records*test_fraction):]\n",
    "x_train, y_train = word_vectors[train_split,:], labels.values[train_split,:]\n",
    "x_test, y_test = word_vectors[test_split,:], labels.values[test_split]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "type(x_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(word_vectors,labels.values,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10000)\n",
      "(20000, 2)\n",
      "(5000, 10000)\n",
      "(5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "type(x_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic MNIST\n",
    "learning_rate = 0.1 \n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 10000 # MNIST data input (img shape: 28*28 flattened to be 784)\n",
    "n_hidden_1 = 100 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "n_hidden_3 = 100 # 2nd layer number of neurons\n",
    "n_classes = 2 # MNIST classes for prediction(digits 0-9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(n_input,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Dense_1\")(Inp)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Dense_2\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Dense_3\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 100)               1000100   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Outputlayer (Dense)          (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,020,502\n",
      "Trainable params: 1,020,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 4s - loss: 0.6688 - acc: 0.5906 - val_loss: 0.5576 - val_acc: 0.8064\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.5253 - acc: 0.7581 - val_loss: 0.4255 - val_acc: 0.8500\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.4514 - acc: 0.8066 - val_loss: 0.3777 - val_acc: 0.8746\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.4048 - acc: 0.8361 - val_loss: 0.3740 - val_acc: 0.8702\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.3768 - acc: 0.8518 - val_loss: 0.4016 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.3613 - acc: 0.8596 - val_loss: 0.3750 - val_acc: 0.8738\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.3431 - acc: 0.8725 - val_loss: 0.3766 - val_acc: 0.8742\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 4s - loss: 0.3267 - acc: 0.8758 - val_loss: 0.3599 - val_acc: 0.8748\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.3095 - acc: 0.8847 - val_loss: 0.3228 - val_acc: 0.8886\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s - loss: 0.3050 - acc: 0.8889 - val_loss: 0.3448 - val_acc: 0.8790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191f454a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11848659,  0.88151342],\n",
       "       [ 0.46512419,  0.53487581],\n",
       "       [ 0.11195334,  0.88804668],\n",
       "       [ 0.52787238,  0.47212759],\n",
       "       [ 0.18762611,  0.81237382]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11848659,  0.88151342],\n",
       "       [ 0.46512419,  0.53487581],\n",
       "       [ 0.11195334,  0.88804668],\n",
       "       [ 0.52787238,  0.47212759],\n",
       "       [ 0.18762611,  0.81237382]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_on_batch(x_test[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
