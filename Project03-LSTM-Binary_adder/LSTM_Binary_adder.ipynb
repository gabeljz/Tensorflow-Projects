{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary adder model\n",
    "\n",
    "### Inputs\n",
    "\n",
    "* Interger between **0 to 100**\n",
    "* Convert to an **array of bits** to represent the number in **binary**\n",
    "* Referred to as **input1** and **input2**\n",
    "\n",
    "### Result\n",
    "\n",
    "* Interger between **0 to 200**\n",
    "* Convert to an **array of bits** to represent the number in **binary**\n",
    "* Referred to as **result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.8\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_operands_and_sums(operand):\n",
    "    operand = operand.astype(\"uint8\")\n",
    "    sums = []\n",
    "    for operand1 in operand:\n",
    "        for operand2 in operand:\n",
    "            sums.append(np.unpackbits(operand1 + operand2))\n",
    "\n",
    "    operands = []\n",
    "    for operand1 in operand:\n",
    "        for operand2 in operand:\n",
    "            operands.append([np.unpackbits(operand1), np.unpackbits(operand2)])            \n",
    "            \n",
    "    operands = np.array(operands, dtype=np.uint8)\n",
    "    \n",
    "    operands_transpose = []\n",
    "    \n",
    "    for operand in operands:\n",
    "        operands_transpose.append(operand.T[::-1])\n",
    "        \n",
    "    operands_transpose = np.array(operands_transpose, dtype=np.uint8)\n",
    "    sums = np.array(sums, dtype=np.uint8)\n",
    "    sums = np.flip(sums, 1)\n",
    "#     operands = np.unpackbits(operands, axis=1)\n",
    "#     sums = np.unpackbits(sums)\n",
    "    return (operands_transpose, sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10201\n",
      "10201\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "[0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate the full set of integers between 0 and 100 as operand\n",
    "operand = np.arange(0, 101);\n",
    "operands, sums = get_operands_and_sums(operand);\n",
    "\n",
    "print(len(operands))\n",
    "print(len(sums))\n",
    "print(operands[10200])\n",
    "print(sums[10200])\n",
    "\n",
    "number_of_records = len(operands)\n",
    "shuffle = np.arange(number_of_records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.8\n",
    "\n",
    "# print(shuffle)\n",
    "\n",
    "#making a train / test split\n",
    "train_split, test_split = shuffle[:int(number_of_records*test_fraction)], shuffle[int(number_of_records*test_fraction):]\n",
    "# print(train_split)\n",
    "# print(test_split)\n",
    "x_train , y_train = operands[train_split,:] , sums[train_split]\n",
    "x_test , y_test = operands[test_split,:] , sums[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a subset of integers between 0 and 100 as operand\n",
    "\n",
    "# fifties = np.empty(100)\n",
    "# fifties.fill(50)\n",
    "# x_train , y_train = get_operands_and_sums(fifties);\n",
    "\n",
    "# multiples_of_two = np.arange(0, 101, 2)\n",
    "# x_train , y_train = get_operands_and_sums(multiples_of_two);\n",
    "\n",
    "# zero_to_hundred = np.arange(0, 101);\n",
    "# x_test , y_test = get_operands_and_sums(zero_to_hundred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8160, 8, 2)\n",
      "(8160, 8)\n",
      "(2041, 8, 2)\n",
      "(2041, 8)\n",
      "[[1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "[0 0 1 1 0 0 0 0]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]]\n",
      "[1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# x_train = x_train.reshape(len(x_train), 8, 2)\n",
    "# x_test = x_test.reshape(len(x_test), 8, 2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train[1])\n",
    "print(y_train[1])\n",
    "print(x_test[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our input shape is  (8, 2)\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "print('our input shape is ',(x_train.shape[1], x_train.shape[2]) )\n",
    "x = LSTM(16)(inp)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = LSTM(256)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "output = Dense(y_train.shape[1], activation ='sigmoid')(x)\n",
    "\n",
    "# 1 x LSTM(256) - val_acc at 1.0000 after 26 epochs\n",
    "# 1 x LSTM(32) - val_acc at 0.9994 after 32 epochs\n",
    "# 1 x LSTM(24) - val_acc at 1.0000 after 73 epochs\n",
    "# 1 x LSTM(16) - val_acc at 0.9991 after 26 epochs\n",
    "# 1 x LSTM(16) - val_acc at 0.9992 after 66 epochs\n",
    "# 1 x LSTM(16) - val_acc at 0.9998 after 71 epochs\n",
    "# 1 x LSTM(16) - val_acc at 0.9998 after 126 epochs\n",
    "# 1 x LSTM(8) - val_acc at 0.8902 after 115 epochs\n",
    "# 1 x LSTM(8) - val_acc at 0.9207 after 327 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                1216      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 1,352\n",
      "Trainable params: 1,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.01)\n",
    "generative_model = Model(inputs = inp, outputs=output )\n",
    "generative_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "generative_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8160 samples, validate on 2041 samples\n",
      "Epoch 1/500\n",
      "8160/8160 [==============================] - 3s - loss: 0.6599 - acc: 0.5464 - val_loss: 0.5962 - val_acc: 0.6142\n",
      "Epoch 2/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.5143 - acc: 0.6878 - val_loss: 0.4239 - val_acc: 0.7575\n",
      "Epoch 3/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.3940 - acc: 0.7787 - val_loss: 0.3193 - val_acc: 0.8226\n",
      "Epoch 4/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.3016 - acc: 0.8411 - val_loss: 0.2268 - val_acc: 0.9010\n",
      "Epoch 5/500\n",
      "8160/8160 [==============================] - 3s - loss: 0.2273 - acc: 0.8945 - val_loss: 0.1509 - val_acc: 0.9381\n",
      "Epoch 6/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.1768 - acc: 0.9166 - val_loss: 0.1164 - val_acc: 0.9501\n",
      "Epoch 7/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.1522 - acc: 0.9357 - val_loss: 0.0841 - val_acc: 0.9873\n",
      "Epoch 8/500\n",
      "8160/8160 [==============================] - 3s - loss: 0.1158 - acc: 0.9623 - val_loss: 0.0351 - val_acc: 0.9985\n",
      "Epoch 9/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0823 - acc: 0.9725 - val_loss: 0.0208 - val_acc: 0.9990\n",
      "Epoch 10/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0713 - acc: 0.9758 - val_loss: 0.0163 - val_acc: 0.9990\n",
      "Epoch 11/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0661 - acc: 0.9774 - val_loss: 0.1815 - val_acc: 0.9433\n",
      "Epoch 12/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.1272 - acc: 0.9578 - val_loss: 0.0131 - val_acc: 0.9990\n",
      "Epoch 13/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0621 - acc: 0.9783 - val_loss: 0.0099 - val_acc: 0.9990\n",
      "Epoch 14/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0560 - acc: 0.9798 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "Epoch 15/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0547 - acc: 0.9797 - val_loss: 0.0070 - val_acc: 0.9991\n",
      "Epoch 16/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0499 - acc: 0.9823 - val_loss: 0.0061 - val_acc: 0.9991\n",
      "Epoch 17/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0479 - acc: 0.9826 - val_loss: 0.0053 - val_acc: 0.9991\n",
      "Epoch 18/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0462 - acc: 0.9831 - val_loss: 0.0048 - val_acc: 0.9991\n",
      "Epoch 19/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0441 - acc: 0.9843 - val_loss: 0.0043 - val_acc: 0.9991\n",
      "Epoch 20/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0432 - acc: 0.9836 - val_loss: 0.0042 - val_acc: 0.9991\n",
      "Epoch 21/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0422 - acc: 0.9838 - val_loss: 0.0036 - val_acc: 0.9991\n",
      "Epoch 22/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0424 - acc: 0.9833 - val_loss: 0.0035 - val_acc: 0.9991\n",
      "Epoch 23/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0398 - acc: 0.9849 - val_loss: 0.0032 - val_acc: 0.9991\n",
      "Epoch 24/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0400 - acc: 0.9844 - val_loss: 0.0030 - val_acc: 0.9991\n",
      "Epoch 25/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0392 - acc: 0.9847 - val_loss: 0.0034 - val_acc: 0.9991\n",
      "Epoch 26/500\n",
      "8160/8160 [==============================] - 2s - loss: 0.0384 - acc: 0.9848 - val_loss: 0.0032 - val_acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12938ac50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"checkpoints/Recurrent_binary_adder_dense-weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min') # , verbose=1\n",
    "reduce_LR = ReduceLROnPlateau(monitor='loss',factor = 0.9, patience=3,cooldown=2, min_lr = 0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10) #, min_delta=0.0001)\n",
    "callbacks_list = [checkpoint, reduce_LR, early_stopping]\n",
    "\n",
    "generative_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.23107485e-04   2.81765952e-05   9.95644212e-01   3.92717411e-05\n",
      "    9.99968052e-01   9.99753535e-01   9.99830365e-01   3.09400548e-06]\n",
      " [  9.99831796e-01   9.99978065e-01   3.34606170e-06   2.41872817e-06\n",
      "    9.99943852e-01   9.99893665e-01   9.99286592e-01   2.02143679e-06]\n",
      " [  9.98846054e-01   6.32932293e-04   6.68778142e-04   9.97909129e-01\n",
      "    3.21618631e-04   9.98268127e-01   3.57295765e-04   9.99992967e-01]\n",
      " [  3.48598114e-04   4.84240329e-04   3.11524118e-03   9.91398335e-01\n",
      "    9.99918103e-01   5.21747395e-04   9.99932408e-01   4.46210606e-06]\n",
      " [  6.68367837e-04   9.99589264e-01   1.13592658e-03   7.03941532e-06\n",
      "    9.99876142e-01   1.42907968e-03   6.50802278e-04   9.99993563e-01]]\n",
      "[[ 46]\n",
      " [206]\n",
      " [149]\n",
      " [ 26]\n",
      " [ 73]]\n",
      "[[ 46]\n",
      " [206]\n",
      " [149]\n",
      " [ 26]\n",
      " [ 73]]\n"
     ]
    }
   ],
   "source": [
    "preds = generative_model.predict(x_test[0:5]);\n",
    "\n",
    "print(preds)\n",
    "\n",
    "for pred in preds:\n",
    "    pred[pred>=0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    \n",
    "preds = preds.astype(\"uint8\");\n",
    "\n",
    "print(np.packbits(preds, -1))\n",
    "print(np.packbits(y_test[0:5], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8160, 8, 2)\n",
      "(8160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our input shape is  (8, 2)\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "print('our input shape is ',(x_train.shape[1], x_train.shape[2]) )\n",
    "x = LSTM(6, return_sequences=True)(inp)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = LSTM(256)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "# print(x.shape)\n",
    "output = TimeDistributed(Dense(1, activation ='sigmoid'))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 8, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8, 6)              216       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 6)              0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 1)              7         \n",
      "=================================================================\n",
      "Total params: 223\n",
      "Trainable params: 223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# adam = Adam(lr=0.01)\n",
    "timedistributed_model = Model(inputs = inp, outputs=output )\n",
    "timedistributed_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "timedistributed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8160, 8)\n",
      "(8160, 8, 1)\n",
      "(2041, 8)\n",
      "(2041, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train_3D = y_train.reshape(y_train.shape[0], y_train.shape[1],  1)\n",
    "print(y_train.shape)\n",
    "print(y_train_3D.shape)\n",
    "y_test_3D = y_test.reshape(y_test.shape[0], y_test.shape[1], 1)\n",
    "print(y_test.shape)\n",
    "print(y_test_3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8160 samples, validate on 2041 samples\n",
      "Epoch 1/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6923 - acc: 0.5275 - val_loss: 0.6883 - val_acc: 0.5040\n",
      "Epoch 2/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6855 - acc: 0.5271 - val_loss: 0.6806 - val_acc: 0.5047\n",
      "Epoch 3/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6759 - acc: 0.5596 - val_loss: 0.6674 - val_acc: 0.5658\n",
      "Epoch 4/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6615 - acc: 0.6001 - val_loss: 0.6481 - val_acc: 0.6161\n",
      "Epoch 5/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6413 - acc: 0.6249 - val_loss: 0.6238 - val_acc: 0.6326\n",
      "Epoch 6/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.6197 - acc: 0.6560 - val_loss: 0.5966 - val_acc: 0.7413\n",
      "Epoch 7/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.5928 - acc: 0.6900 - val_loss: 0.5637 - val_acc: 0.7501\n",
      "Epoch 8/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.5611 - acc: 0.7123 - val_loss: 0.5263 - val_acc: 0.7929\n",
      "Epoch 9/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.5241 - acc: 0.7573 - val_loss: 0.4816 - val_acc: 0.8481\n",
      "Epoch 10/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.4795 - acc: 0.8068 - val_loss: 0.4324 - val_acc: 0.8867\n",
      "Epoch 11/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.4323 - acc: 0.8452 - val_loss: 0.3837 - val_acc: 0.9133\n",
      "Epoch 12/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.3875 - acc: 0.8748 - val_loss: 0.3408 - val_acc: 0.9308\n",
      "Epoch 13/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.3508 - acc: 0.8943 - val_loss: 0.3038 - val_acc: 0.9439\n",
      "Epoch 14/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.3195 - acc: 0.9068 - val_loss: 0.2718 - val_acc: 0.9463\n",
      "Epoch 15/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.2908 - acc: 0.9148 - val_loss: 0.2459 - val_acc: 0.9481\n",
      "Epoch 16/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.2670 - acc: 0.9199 - val_loss: 0.2240 - val_acc: 0.9493\n",
      "Epoch 17/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.2501 - acc: 0.9216 - val_loss: 0.2061 - val_acc: 0.9495\n",
      "Epoch 18/1000\n",
      "8160/8160 [==============================] - 3s - loss: 0.2332 - acc: 0.9229 - val_loss: 0.1910 - val_acc: 0.9497\n",
      "Epoch 19/1000\n",
      "8160/8160 [==============================] - 3s - loss: 0.2193 - acc: 0.9244 - val_loss: 0.1778 - val_acc: 0.9497\n",
      "Epoch 20/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.2082 - acc: 0.9244 - val_loss: 0.1656 - val_acc: 0.9497\n",
      "Epoch 21/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1958 - acc: 0.9255 - val_loss: 0.1543 - val_acc: 0.9497\n",
      "Epoch 22/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1852 - acc: 0.9270 - val_loss: 0.1437 - val_acc: 0.9497\n",
      "Epoch 23/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1756 - acc: 0.9275 - val_loss: 0.1335 - val_acc: 0.9497\n",
      "Epoch 24/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1656 - acc: 0.9285 - val_loss: 0.1237 - val_acc: 0.9498\n",
      "Epoch 25/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1558 - acc: 0.9292 - val_loss: 0.1147 - val_acc: 0.9498\n",
      "Epoch 26/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1476 - acc: 0.9297 - val_loss: 0.1065 - val_acc: 0.9498\n",
      "Epoch 27/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1399 - acc: 0.9313 - val_loss: 0.0990 - val_acc: 0.9498\n",
      "Epoch 28/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1330 - acc: 0.9301 - val_loss: 0.0922 - val_acc: 0.9498\n",
      "Epoch 29/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1257 - acc: 0.9367 - val_loss: 0.0856 - val_acc: 0.9741\n",
      "Epoch 30/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1191 - acc: 0.9541 - val_loss: 0.0797 - val_acc: 0.9941\n",
      "Epoch 31/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1124 - acc: 0.9653 - val_loss: 0.0743 - val_acc: 0.9998\n",
      "Epoch 32/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1077 - acc: 0.9674 - val_loss: 0.0695 - val_acc: 1.0000\n",
      "Epoch 33/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.1023 - acc: 0.9709 - val_loss: 0.0648 - val_acc: 1.0000\n",
      "Epoch 34/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0968 - acc: 0.9738 - val_loss: 0.0604 - val_acc: 1.0000\n",
      "Epoch 35/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0914 - acc: 0.9782 - val_loss: 0.0562 - val_acc: 1.0000\n",
      "Epoch 36/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0879 - acc: 0.9810 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 37/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0841 - acc: 0.9807 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 38/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0800 - acc: 0.9813 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 39/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0763 - acc: 0.9815 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 40/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0727 - acc: 0.9824 - val_loss: 0.0400 - val_acc: 1.0000\n",
      "Epoch 41/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0699 - acc: 0.9825 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 42/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0682 - acc: 0.9815 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 43/1000\n",
      "8160/8160 [==============================] - 2s - loss: 0.0646 - acc: 0.9826 - val_loss: 0.0331 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12989bef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 x LSTM(2) - val_acc at 0.7381 after 27 epochs\n",
    "# 1 x LSTM(4) - val_acc at 0.9483 after 52 epochs\n",
    "# 1 x LSTM(4) - val_acc at 0.9484 after 17 epochs\n",
    "# 1 x LSTM(5) - val_acc at 0.9958 after 1000 epochs\n",
    "# 1 x LSTM(5) - val_acc at 0.9972 after 2000 epochs\n",
    "# 1 x LSTM(5) - val_acc at 0.9987 after 3000 epochs\n",
    "# 1 x LSTM(5) - val_acc at 0.9990 after 3291 - 4000 epochs\n",
    "# 1 x LSTM(6) - val_acc at 0.9490 after 35 epochs\n",
    "# 1 x LSTM(6) - val_acc at 1.0000 after 14 epochs\n",
    "# 1 x LSTM(6) - val_acc at 1.0000 after 15 epochs\n",
    "# 1 x LSTM(8) - val_acc at 1.0000 after 39 epochs\n",
    "# 1 x LSTM(256) - val_acc at 1.0000 after 24 epochs\n",
    "\n",
    "filepath=\"checkpoints/Recurrent_binary_adder_timedistributed-weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min')\n",
    "reduce_LR = ReduceLROnPlateau(monitor='loss',factor = 0.9, patience=3,cooldown=2, min_lr = 0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10) #, min_delta=0.0001)\n",
    "callbacks_list = [checkpoint, reduce_LR, early_stopping]\n",
    "\n",
    "timedistributed_model.fit(\n",
    "    x_train, y_train_3D,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test, y_test_3D),\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46]\n",
      " [206]\n",
      " [149]\n",
      " [ 26]\n",
      " [ 73]]\n",
      "[[ 46]\n",
      " [206]\n",
      " [149]\n",
      " [ 26]\n",
      " [ 73]]\n"
     ]
    }
   ],
   "source": [
    "# timedistributed_model.save(\"timedistributed_model-lstm6-1_0000.model\")\n",
    "timedistributed_model = load_model(\"timedistributed_model-lstm6-1_0000.model\")\n",
    "preds = timedistributed_model.predict(x_test[0:5]);\n",
    "\n",
    "# print(preds)\n",
    "# print(y_test_3D[0:5])\n",
    "preds = preds.reshape(preds.shape[0], 8)\n",
    "\n",
    "for pred in preds:\n",
    "    pred[pred>=0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    \n",
    "preds = preds.astype(\"uint8\");\n",
    "\n",
    "# print(preds)\n",
    "print(np.packbits(preds, -1))\n",
    "print(np.packbits(y_test_3D[0:5].reshape(5, 8), -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
